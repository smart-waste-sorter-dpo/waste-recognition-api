version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: deploy/Dockerfile.dev
    ports:
      - target: 8000
        published: 8000
        protocol: tcp
        mode: host
    volumes:
      - .:/src
    environment:
      - DEBUG=True
      - MODEL_SERVER_HOST=tf_serving
    depends_on:
      - tf_serving
    restart: unless-stopped

  tf_serving:
    image: tensorflow/serving
    ports:
      - "8501:8501"
    volumes:
      - ./src/models:/models
    environment:
      - MODEL_NAME=trash_classification_model
    restart: unless-stopped
